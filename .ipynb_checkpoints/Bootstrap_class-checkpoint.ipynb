{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d72848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bootstrap:\n",
    "    '''\n",
    "    Basic statistics tests using bootstraping.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    data_1 : \n",
    "        1d numpy ndarray or pandas Series\n",
    "        \n",
    "    data_2 : \n",
    "        1d numpy ndarray or pandas Series (optional)\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    one_sample_test(one_sample_mean, size=1000, alternative='two-sided')\n",
    "        Calculate p-value comparing data_1 sample to given mean value.\n",
    "        \n",
    "    two_sample_test(size=1000, alternative='two-sided')\n",
    "        Calculate p-value comparing data_1 and data_2 mean values.\n",
    "        \n",
    "    permutation_test(size=1000, alternative='two-sided')\n",
    "        Calculate p-value comparing data_1 and data_2 mean values.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, _data_1, _data_2=np.empty(0), nans='drop'):\n",
    "        \n",
    "        # check if user has imported needed libraries to run the code\n",
    "        import sys\n",
    "        modulename = ['numpy', 'pandas']\n",
    "        for module in modulename:\n",
    "            if module not in sys.modules:\n",
    "                raise ImportError(f'You have not imported the {module} module.')\n",
    "        \n",
    "        # class is based on numpy, thus check the type and convert to ndarray\n",
    "        if isinstance(_data_1, (pd.DataFrame, pd.Series, list)) or\\\n",
    "           isinstance(_data_2, (pd.DataFrame, pd.Series, list)):\n",
    "            _data_1, _data_2 = np.array(_data_1), np.array(_data_2)\n",
    "        \n",
    "        # data must be 1-dimentional\n",
    "        if ((_data_1.ndim > 1) and (1 not in _data_1.shape)) or\\\n",
    "           ((_data_2.ndim > 1) and (1 not in _data_2.shape)):\n",
    "            raise ValueError('Data must be 1-dimentional.')\n",
    "        \n",
    "        # check for nans and proceed based on input\n",
    "        tmp_data = []\n",
    "        for data in [_data_1, _data_2]:\n",
    "            if np.isnan(data).any():\n",
    "                # store the data as bool values where nan = true\n",
    "                nan_bool = np.isnan(data).flatten()\n",
    "                if nans == 'drop':\n",
    "                    # drop the nan values\n",
    "                    data = np.delete(data, nan_bool)\n",
    "                elif nans == 'mean':\n",
    "                    # impute using mean value\n",
    "                    data[np.isnan(data)] = np.delete(data, nan_bool).mean()\n",
    "                elif nans == 'median':\n",
    "                    # impute using median value\n",
    "                    data[np.isnan(data)] = np.median(np.delete(data, nan_bool))\n",
    "                elif nans == 'most_frequent':\n",
    "                    # get unique and count vectors\n",
    "                    unique, count = np.unique(np.delete(data, nan_bool), return_counts=True)\n",
    "                    # impute with the most frequent value\n",
    "                    data[np.isnan(data)] = unique[count.max()]\n",
    "            tmp_data.append(data)\n",
    "        \n",
    "        # if everything is ok store the data\n",
    "        self._data = tmp_data\n",
    "        \n",
    "        # here is a place for the proper code that is yet to be added\n",
    "        # as of now pd.Series data types will not work properly or at all.\n",
    "        # also the part for dealing with nans based on imputing method should be added\n",
    "        \n",
    "        \n",
    "        # add more statistical tests, like chi2 or F-test for anova based on bootstrap\n",
    "        \n",
    "        # add pairs_bootstrap (lin_reg, corr, r^2, F, etc.)\n",
    "        \n",
    "        # 'alternative' parameter wokrs okey, but 'less' and 'greater' should be added\n",
    "        # as the methods will always try to get more extreme values to calculate one-sided p_value\n",
    "        \n",
    "        # add descriptions for methods\n",
    "        \n",
    "        # add method for confidence intervals estimation\n",
    "        \n",
    "        # add method for drawing bootstrap samples without tests\n",
    "        \n",
    "        # add method for creating permutation sample w/o any test\n",
    "    \n",
    "    ######################################### BASIC METHODS ###############################################################\n",
    "    \n",
    "    def bootstrap_sample(self, size=1000, func=np.mean):\n",
    "        \n",
    "        # if data_2 is present extract only data_1\n",
    "        if self._data[1].size != 0:\n",
    "            d = self._data[0]\n",
    "            \n",
    "        # sample from the data\n",
    "        samples = func(\n",
    "            np.random.choice(d, size=(d.shape[0], size)), \n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        # store the result in self\n",
    "        self.bs_samples_ = samples\n",
    "        \n",
    "        # return\n",
    "        return samples\n",
    "    \n",
    "    def pair_bootstrap_sample(self, size=1000, to_return='sample'):\n",
    "        \n",
    "        # we can return sample as a set of matrices\n",
    "        # parameters a and b\n",
    "        # or both\n",
    "        # add pairs_bootstrap (lin_reg, corr, r^2, F, etc.)\n",
    "        \n",
    "        # create a pair bootstrap\n",
    "        a_b = np.empty(10000)\n",
    "        for i in range(10000):\n",
    "        \n",
    "            # get the indices\n",
    "            ind = np.random.choice(np.arange(lane.size), size=lane.size)\n",
    "            \n",
    "            # subsett and recalculate slope and interception\n",
    "            x_ind, y_ind = lane[ind], f_13[ind]\n",
    "            a_b[i, :] = np.polyfit(x_ind, y_ind, deg=1)\n",
    "    \n",
    "    \n",
    "    def ci(self, _CI=[2.5, 97.5], *args):\n",
    "        \n",
    "        row = self._data.shape[0]\n",
    "        variable = np.empty((row, len(_CI)))\n",
    "        \n",
    "        for i, d in enumerate(self._data):\n",
    "            variable[i, :] = np.percentile(d, _CI)\n",
    "            \n",
    "        return variable\n",
    "    \n",
    "    ######################################### STATISTICS HYPOTHESES TEST ##################################################\n",
    "    \n",
    "    def one_sample_test(self, one_sample_mean, size=1000, alternative='two-sided'):\n",
    "            \n",
    "        # if data_2 is present extract only data_1\n",
    "        if self._data[1].size != 0:\n",
    "            d = self._data[0]\n",
    "        \n",
    "        # transform the data\n",
    "        # dost = data_one_sample_transformed\n",
    "        dost = d - np.mean(d) + one_sample_mean\n",
    "        \n",
    "        # sample from the data\n",
    "        bs_dost = np.random.choice(dost, size=(dost.shape[0], size)).mean(axis=0)\n",
    "        \n",
    "        # store the result in self\n",
    "        self.bs_one_sample_ = bs_dost\n",
    "        \n",
    "        # calculate p-value\n",
    "        if bs_dost.mean() < d.mean():\n",
    "            self.one_sample_pval_ = (bs_dost >= d.mean()).sum() / bs_dost.shape[0]\n",
    "        else:\n",
    "            self.one_sample_pval_ = (bs_dost <= d.mean()).sum() / bs_dost.shape[0]\n",
    "        \n",
    "        # return p-value\n",
    "        if alternative == 'two-sided':\n",
    "            return 2 * self.one_sample_pval_\n",
    "        else:\n",
    "            return self.one_sample_pval_\n",
    "    \n",
    "    def two_sample_test(self, size=1000, alternative='two-sided'):\n",
    "        \n",
    "        # extract the data into easily manageable variables\n",
    "        if self._data[1].size == 0:\n",
    "            raise ValueError('Second data sample is empty.')\n",
    "        else:\n",
    "            d_1 = self._data[0]\n",
    "            d_2 = self._data[1]\n",
    "        \n",
    "        # store the value of difference between sample means\n",
    "        diff_obs = d_1.mean() - d_2.mean()\n",
    "        \n",
    "        # concatenate the data samples and calculate the mean\n",
    "        # cdsm  = concatenated_data_samples_mean\n",
    "        cdsm = np.concatenate([d_1, d_2]).mean()\n",
    "        \n",
    "        # transform the data samples to have the value of mean equal to cdsm\n",
    "        # tds_i = transformed_data_sample_i\n",
    "        tds_1 = d_1 - d_1.mean() + cdsm\n",
    "        tds_2 = d_2 - d_2.mean() + cdsm\n",
    "        \n",
    "        # bootstrap mean values from the tds_i and store it\n",
    "        # bsm_i = bootstrap_mean_i\n",
    "        bsm_1 = np.random.choice(tds_1, size=(tds_1.shape[0], size)).mean(axis=0)\n",
    "        bsm_2 = np.random.choice(tds_2, size=(tds_2.shape[0], size)).mean(axis=0)\n",
    "            \n",
    "        # store the differences\n",
    "        # bsmd = bootstrap_mean_difference\n",
    "        bsmd = bsm_1 - bsm_2\n",
    "            \n",
    "        # store bsmd in self\n",
    "        self.bs_two_sample_diff_ = bsmd\n",
    "        \n",
    "        # calculate p-value\n",
    "        if bsmd.mean() < diff_obs:\n",
    "            self.two_sample_pval_ = (bsmd >= diff_obs).sum() / bsmd.shape[0]\n",
    "        else:\n",
    "            self.two_sample_pval_ = (bsmd <= diff_obs).sum() / bsmd.shape[0]\n",
    "            \n",
    "        # return p-value\n",
    "        if alternative == 'two-sided':\n",
    "            return 2 * self.two_sample_pval_\n",
    "        else:\n",
    "            return self.two_sample_pval_\n",
    "        \n",
    "    def permutation_test(self, size=1000, alternative='two-sided'):\n",
    "        '''It assumes that the sets are identicaly distributed.'''\n",
    "        \n",
    "        # alternate function could be added to calculate different test statistics than differences of something\n",
    "        # for example pearson correlation coefficient\n",
    "        \n",
    "        if self._data[1].size == 0:\n",
    "            raise ValueError('Second data sample is empty.')\n",
    "        else:\n",
    "            d_1 = self._data[0]\n",
    "            d_2 = self._data[1]\n",
    "            \n",
    "        # calculate the observable mean difference between two samples\n",
    "        diff_obs = d_1.mean() - d_2.mean()\n",
    "        \n",
    "        # concatenate the samples\n",
    "        # cds = concatenated_data_samples\n",
    "        cds = np.concatenate([d_1, d_2])\n",
    "        \n",
    "        # permutate and separate the data into two sets\n",
    "        # then calculate the difference between means and store the values\n",
    "        \n",
    "        # perm is a matrix of shape size X cds.size\n",
    "        perm = np.array([np.random.permutation(cds) for _ in range(size)])\n",
    "        \n",
    "        # separate the data\n",
    "        perm_1, perm_2 = perm[:, :d_1.shape[0]], perm[:, d_1.shape[0]:]\n",
    "        \n",
    "        # calculate and store the difference in means\n",
    "        # pmd = permutation_mean_difference\n",
    "        pmd = perm_1.mean(axis=1) - perm_2.mean(axis=1)\n",
    "        \n",
    "        ####\n",
    "        # worth checking if doing it as np.diff(perm.reshape(size, int(cds.size * 0.5), 2).mean(axis=1) if d1.size == d2.size\n",
    "        # is faster than what's above\n",
    "        ####\n",
    "\n",
    "        #for i in range(size):\n",
    "        #    # permutate the cds set\n",
    "        #    perm = np.random.permutation(cds)\n",
    "        #    \n",
    "        #    # separate\n",
    "        #    perm_reshaped = perm.reshape(-1, 2) # <--- it only supports arrays of the same shape, that can be split in half\n",
    "        #    \n",
    "        #    # calculate and store the difference in means         \n",
    "        #    pmd[i] = np.diff(perm_reshaped.mean(axis=0))\n",
    "            \n",
    "        # store the differences\n",
    "        self.bs_permutation_diff_ = pmd\n",
    "        \n",
    "        # calculate p-value\n",
    "        if pmd.mean() < diff_obs:\n",
    "            self.permutation_pval_ = (pmd >= diff_obs).sum() / pmd.size\n",
    "        else:\n",
    "            self.permutation_pval_ = (pmd <= diff_obs).sum() / pmd.size\n",
    "            \n",
    "        # return p-value\n",
    "        if alternative == 'two-sided':\n",
    "            return 2 * self.permutation_pval_\n",
    "        else:\n",
    "            return self.permutation_pval_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
